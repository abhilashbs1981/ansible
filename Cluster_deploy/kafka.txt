http://elastic-elasticsearch:9200

https://github.com/quickbooks2018/kafka-bitnami

helm pull bitnami/kafka --version 23.0.7

image:
  debug: true
replicaCount: 3
tolerations:
   - key: "node-role.kubernetes.io/control-plane"
     operator: "Equal"
     value: ""
     effect: "NoSchedule"
externalAccess:
  enabled: false
  autoDiscovery:
    enabled: true
kraft:
  enabled: false
extraEnvVars:
  - name: KAFKA_ENABLE_KRAFT
    value: "false"
  - name: KAFKA_CFG_DELETE_TOPIC_ENABLE
    value: "true"  # Add this line to enable topic deletion
  - name: KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE
    value: "true"  # Add this line to enable topic auto-creation
zookeeper:
  enabled: true
  replicaCount: 3
  persistence:
    enabled: true
    size: 2Gi


helm install kafka . --set persistence.size=2Gi,logPersistence.size=2Gi,volumePermissions.enabled=true,persistence.enabled=true,logPersistence.enabled=true,serviceAccount.create=true,rbac.create=true  -f  values.yaml

Kafka Topic creation
kafka-topics.sh --create --topic test1 --bootstrap-server kafka.default.svc.cluster.local:9092
kafka-topics.sh --create --topic test2 --bootstrap-server kafka.default.svc.cluster.local:9092
kafka-topics.sh --create --topic test3 --bootstrap-server kafka.default.svc.cluster.local:9092



Kafka verify the cluster using producer and consumer
	Kafka Add mesgs to the topic 
	kafka-console-producer.sh --broker-list kafka-0.kafka-headless.default.svc.cluster.local:9092  --topic test1
	Kafka Check and verify the msgs 
	kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test1 --from-beginning

Kafka to delete msgs from the topic 
 
cat > offsetfile.json << EOF
{"partitions": [{"topic": "test1", "partition": 0, "offset": 3461}], "version":1 }
EOF

kafka-delete-records.sh --bootstrap-server localhost:9092 --offset-json-file ./offsetfile.json

Kafka to count the number of msgs in topic 

kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list localhost:9092 --topic test1 --time -1 | awk -F ":" '{sum += $3} END {print sum}'
 
kubectl taint node master node-role.kubernetes.io/master:NoSchedule
kubectl taint node master node-role.kubernetes.io/master:NoSchedule-

kafka-consumer-groups.sh --bootstrap-server localhost:9092 --all-groups -describe
 
*****************************************************************************************************

JMX_PORT=0

Create topic
kafka-topics.sh --create --topic test1 --bootstrap-server localhost:9092
List all topics 
kafka-topics.sh --bootstrap-server localhost:9092 --list

Put records into topic 
echo "Hello, world25!" | kafka-console-producer.sh --broker-list localhost:9092 --topic test1
Read record from the topic 
kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test1 --from-beginning
 
Count the number of records in the topic 
kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list localhost:9092 --topic test1 --time -1 | awk -F ":" '{sum += $3} END {print sum}'

 

 

******************************************************************************************* 



5.1. Verificare ca Elasticsearch functioneaza:
curl -XGET elastic-elasticsearch:9200
5.1. Testare Elasticsearch:
# Download mapping for index
sudo wget http://media.sundog-soft.com/es8/shakes-mapping.json
curl -H "Content-Type: application/json" -XPUT elastic-elasticsearch:9200/shakespeare --data-binary @shakes-mapping.json
# Download shakespeare data
sudo wget http://media.sundog-soft.com/es8/shakespeare_8.0.json

SPlit the file into 10 before upload
https://jira.telekom.de/browse/FTTH-75241
# Index data Elasticsearch
curl -H "Content-Type: application/json" -XPUT 'elastic-elasticsearch:9200/shakespeare/_bulk' --data-binary @shakespeare_8.0.json
# Cautare
  curl -H "Content-Type: application/json" -XGET 'elastic-elasticsearch:9200/shakespeare/_search?pretty' -d '
                    {
                        "query" : {
                        "match_phrase" : {
                        "text_entry" : "to be or not to be"
                    }
                    }
                    }'



 
    [OUTPUT]
        Name  stdout
        Match *
    [OUTPUT]
        Name es
        Match cpu_metrics
        Host ems-elasticsearch
        Index           soct_logging-$TAG[$INDEX_YEAR]-$TAG[$INDEX_MONTH]-$TAG[$INDEX_DAY]
        Type            cpu_metrics
        HTTP_User       elastic
        HTTP_Passwd     elastic123
        Port 9200
        tls On
        tls.verify      off
        Replace_Dots    On
        Generate_ID     On
        Suppress_Type_Name On
        Retry_Limit False
#        Logstash_Format On
#        Logstash_Prefix soct_logging
#        Time_Key @timestamp



ems-mpmb-kafka.ems.svc.cluster.local









 
